VLLM_API_KEY=changeme
# Optional Hugging Face auth token for gated checkpoints (Meta Llama, etc.)
HF_TOKEN=
# Optional: comma-separated launcher routes to prewarm at startup (e.g., chat,general)
PREWARM_ROUTES=
# Optional: override Docker socket path if not /var/run/docker.sock
# DOCKER_HOST_SOCKET=/var/run/docker.sock
# Optional: keep Open WebUI auth enabled (true) or disable for trusted LANs
OPEN_WEBUI_AUTH=true
# Open WebUI reuses VLLM_API_KEY; no extra token is needed
# Optional: advertise friendly model ids per route for the unified OpenAI endpoint
# MAP__chat__models=chat-general
# MAP__vision__models=vision-diffusion,sd35m,sd15

# Vision diffusion service (Stable Diffusion 3.5 Medium) overrides
VISION_MODEL_ID=stabilityai/stable-diffusion-3.5-medium
# Optional: pin to a specific revision (leave blank for latest main)
VISION_MODEL_REVISION=
# Opt-in HF safety checker (0=disabled, 1=enabled)
VISION_ENABLE_SAFETY_CHECKER=0
# Control tiling / attention slicing toggles (1=enabled, 0=disabled)
VISION_ENABLE_TILING=1
VISION_ENABLE_ATTENTION_SLICING=1
# Maximum allowed width/height in pixels (per edge)
VISION_MAX_EDGE=1024
