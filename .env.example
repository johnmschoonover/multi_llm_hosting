VLLM_API_KEY=changeme
# Optional Hugging Face auth token for gated checkpoints (Meta Llama, etc.)
HF_TOKEN=
# Optional: comma-separated launcher routes to prewarm at startup (e.g., chat,general)
PREWARM_ROUTES=
# Optional: override Docker socket path if not /var/run/docker.sock
# DOCKER_HOST_SOCKET=/var/run/docker.sock
# Optional: keep Open WebUI auth enabled (true) or disable for trusted LANs
OPEN_WEBUI_AUTH=true
# Open WebUI reuses VLLM_API_KEY; no extra token is needed
# Optional: advertise friendly model ids per route for the unified OpenAI endpoint
# MAP__chat__models=chat-general
# MAP__vision__models=vision-diffusion,sd15
